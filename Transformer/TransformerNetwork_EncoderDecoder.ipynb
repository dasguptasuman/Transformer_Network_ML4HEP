{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e99151e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# Train a model to classify real pulses vs. noise\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input,  Dense\n",
    "from tensorflow.keras.models import Model\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import average_precision_score\n",
    "import awkward as ak\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "2703f91d",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_events = 50000\n",
    "num_samples = 10\n",
    "xmin = 1\n",
    "xmax = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "cabe22ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_timesamples(ax, time, emsignal_list, noisedata_list):\n",
    "    #fig, ax = plt.subplots()\n",
    "    for i, emsignal in enumerate(emsignal_list):\n",
    "        noisedata = noisedata_list[i][1:]\n",
    "        ax.plot(time, emsignal[1:], label=f'EM pulse' if i==1 else None, color='blue')\n",
    "        ax.plot(time, noisedata, label=f'noise'  if i==1 else None,color='orange')\n",
    "    ax.set_xlabel('Time (ns)')\n",
    "    ax.set_ylabel('Amplitude (arb. units)')\n",
    "    ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "3e48dc1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.02302645 -0.01106236 -0.04128678 ...  0.43723053  0.23318535\n",
      "   0.12932118]\n",
      " [-0.15864496 -0.07084266  0.00636395 ...  0.49423221  0.3581044\n",
      "   0.25740232]\n",
      " [ 0.05790091  0.03022707  0.09363004 ...  0.92370825  0.81255649\n",
      "   0.68655397]\n",
      " ...\n",
      " [-0.05372396 -0.17839269 -0.17153385 ...  0.37079516  0.16143717\n",
      "   0.06845977]\n",
      " [ 0.13169355  0.31387656  0.36568349 ...  0.7599437   0.6174581\n",
      "   0.39059257]\n",
      " [-0.20073302 -0.15702521 -0.02750234 ...  0.45211461  0.18901024\n",
      "   0.06145787]]\n",
      "Printing y_real\n",
      "[[1.]\n",
      " [1.]\n",
      " [1.]\n",
      " ...\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]]\n"
     ]
    }
   ],
   "source": [
    "import uproot\n",
    "### Energy = 0.15 GeV\n",
    "root_file = uproot.open(f\"/eos/user/d/dasgupsu/SWAN_projects/ECAL_noise_EM_discrimination/data/outputPSWithNoPU_withNoise_0.150000_1.0_v1.root\")\n",
    "tree = root_file[\"Samples\"]\n",
    "arrays = tree.arrays([\"samples\", \"ysamples\",\"samplesNoise\",\"ysamplesNoise\", \"waveforms\"])\n",
    "X_real = ak.to_numpy(arrays[\"samples\"])\n",
    "y_real = ak.to_numpy(arrays[\"ysamples\"])\n",
    "X_noise = ak.to_numpy(arrays[\"samplesNoise\"])\n",
    "y_noise = ak.to_numpy(arrays[\"ysamplesNoise\"])\n",
    "X_waveform = ak.to_numpy(arrays[\"waveforms\"])\n",
    "X_Zero = np.zeros((X_waveform.shape[0], X_waveform.shape[1]), dtype=float)\n",
    "\n",
    "print(X_real) \n",
    "print(\"Printing y_real\")\n",
    "print(y_real)\n",
    "\n",
    "#data = np.concatenate([X_real, X_noise]) ### makes it [2*num_events,num_samples]\n",
    "data = X_real\n",
    "#labels = np.concatenate([y_real,y_noise])\n",
    "labels = y_real\n",
    "#X_target = np.concatenate([X_waveform, X_Zero])\n",
    "X_target = X_waveform\n",
    "# Shuffle data and labels together\n",
    "## Important to shuffle since I take some fraction of events so it should not happen that all the real events \n",
    "## are cluttered at the beginning\n",
    "\n",
    "shuffle_indices = np.random.permutation(len(data))\n",
    "data = data[shuffle_indices]\n",
    "labels = labels[shuffle_indices]\n",
    "X_target = X_target[shuffle_indices]\n",
    "\n",
    "#fig, ax = plt.subplots()\n",
    "import awkward as ak\n",
    "\n",
    "num_events = ak.num(X_real, axis=0)\n",
    "t_events = np.zeros((num_events, num_samples))\n",
    "for i in range(num_events):\n",
    "    t_event = np.linspace(xmin, xmax, 10)\n",
    "    t_events[i] = t_event\n",
    "###replace this block with actual time variable\n",
    "\n",
    "#fig, ax = plt.subplots()\n",
    "#ev_numbers = [1, 2, 3, 4, 5, 6, 7, 8, 9 , 10, 100, 200, 300]# list of event numbers to plot\n",
    "ev_numbers = [1500]\n",
    "emsignal_list = [X_real[ev_number] for ev_number in ev_numbers]\n",
    "noisedata_list = [X_noise[ev_number] for ev_number in ev_numbers]\n",
    "#plot_timesamples(ax, t_events[ev_numbers[0]], emsignal_list, noisedata_list)\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "515e5dce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of rows in data is 50000\n",
      "number of rows in data is 11\n",
      "Size of training data is 35000\n",
      "number of elements in data : training data : test data : test target : train target: 50000 : 35000 : 15000: 15000: 35000\n"
     ]
    }
   ],
   "source": [
    "import awkward as ak\n",
    "\n",
    "num_events_data = ak.num(data, axis=0)\n",
    "print(f'number of rows in data is {num_events_data}')\n",
    "\n",
    "\n",
    "ntimeSamples_data = ak.num(data, axis=1)\n",
    "print(f'number of rows in data is {ntimeSamples_data[0]}') ## just take the 0th event\n",
    "\n",
    "# Split into train and test sets\n",
    "train_size = int(0.7 * num_events_data) ###times 2 because the noise is also in the same dataset, so it is 2*num_events\n",
    "train_data = data[:train_size]\n",
    "train_labels = labels[:train_size]\n",
    "train_target = X_target[:train_size]\n",
    "test_data = data[train_size:]\n",
    "test_labels = labels[train_size:]\n",
    "test_target = X_target[train_size:]\n",
    "print(f'Size of training data is {train_size}')\n",
    "\n",
    "'''\n",
    "print(train_size)\n",
    "print(train_data)\n",
    "print(test_data)\n",
    "'''\n",
    "\n",
    "print(f'number of elements in data : training data : test data : test target : train target: {len(data)} : {len(train_data)} : {len(test_data)}: {len(test_target)}: {len(train_target)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "746e1188",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.08832286, -0.11586289, -0.10912243,  0.0039692 ,  0.63603957,\n",
       "        1.08951627,  1.06605966,  0.91080929,  0.74769153,  0.55507618,\n",
       "        0.36264929])"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "3966ca09",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = train_data\n",
    "y_train = train_labels \n",
    "x_test = test_data\n",
    "y_test = test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "c4a3d9fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_target = train_target.reshape((train_target.shape[0], train_target.shape[1], 1))\n",
    "#test_target = test_target.reshape((test_target.shape[0], test_target.shape[1], 1))\n",
    "train_target = train_target.reshape((train_target.shape[0], train_target.shape[1]))\n",
    "test_target = test_target.reshape((test_target.shape[0], test_target.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "a5db45cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11,)"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_target[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "1eba2687",
   "metadata": {},
   "outputs": [],
   "source": [
    "#x_train = x_train.reshape((x_train.shape[0], x_train.shape[1], 1))\n",
    "#x_test = x_test.reshape((x_test.shape[0], x_test.shape[1], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "4dd65ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_token = 99.*np.ones((x_train.shape[0],1))\n",
    "end_token = -99.*np.ones((x_train.shape[0],1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "17129db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train.reshape((y_train.shape[0],1))\n",
    "y_test = y_test.reshape((y_test.shape[0],1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "c5d7cfec",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "all the input arrays must have same number of dimensions, but the array at index 0 has 2 dimension(s) and the array at index 1 has 3 dimension(s)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_408/1686556886.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_target\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart_token\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_target\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_token\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m#test_target = np.concatenate((start_token, test_target, end_token ), axis=1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/cvmfs/sft.cern.ch/lcg/views/LCG_103cuda/x86_64-centos7-gcc11-opt/lib/python3.9/site-packages/numpy/core/overrides.py\u001b[0m in \u001b[0;36mconcatenate\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: all the input arrays must have same number of dimensions, but the array at index 0 has 2 dimension(s) and the array at index 1 has 3 dimension(s)"
     ]
    }
   ],
   "source": [
    "train_target = np.concatenate((start_token, train_target, end_token ), axis=0)\n",
    "#test_target = np.concatenate((start_token, test_target, end_token ), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "5f60956e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[99.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.5417028 ],\n",
       "       [ 0.96375969],\n",
       "       [ 0.96371202],\n",
       "       [ 0.78764783],\n",
       "       [ 0.58232425],\n",
       "       [ 0.40582712]])"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_target[:, :-2][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "4e4a3787",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.5417028 ],\n",
       "       [0.96375969],\n",
       "       [0.96371202],\n",
       "       [0.78764783],\n",
       "       [0.58232425],\n",
       "       [0.40582712],\n",
       "       [0.27246438]])"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_target[:, 1:-1][3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "380bd6c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer_train = {\"encoder_inputs\": x_train, \"decoder_inputs\": train_target[:, :-2]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "93af4f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = tf.data.Dataset.from_tensor_slices((transformer_train, train_target[:, 1:-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "5b7d1240",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = train_dataset.batch(64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "6185d041",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BatchDataset element_spec=({'encoder_inputs': TensorSpec(shape=(None, 11, 1), dtype=tf.float64, name=None), 'decoder_inputs': TensorSpec(shape=(None, 11, 1), dtype=tf.float64, name=None)}, TensorSpec(shape=(None, 11, 1), dtype=tf.float64, name=None))>"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "e691ec6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Time2Vec(layers.Layer):\n",
    "\n",
    "    def __init__(self, kernel, activation):\n",
    "        super(Time2Vec, self).__init__()\n",
    "        if activation in [\"sin\", \"cos\"]:\n",
    "            activation = {\"sin\": tf.math.sin, \"cos\": tf.math.cos}[activation]\n",
    "\n",
    "        self.k = kernel - 1\n",
    "        self.p_activation = activation\n",
    "\n",
    "    def build(self, input_shape):\n",
    "\n",
    "        # Linear component\n",
    "        self.w_b = self.add_weight(\n",
    "            shape=(1, input_shape[1], 1), initializer=\"uniform\", trainable=True\n",
    "        )\n",
    "\n",
    "        self.b_b = self.add_weight(\n",
    "            shape=(1, input_shape[1], 1), initializer=\"uniform\", trainable=True\n",
    "        )\n",
    "\n",
    "        # Periodic components\n",
    "        self.freq = self.add_weight(\n",
    "            shape=(1, input_shape[1], self.k), initializer=\"uniform\", trainable=True\n",
    "        )\n",
    "\n",
    "        self.phase = self.add_weight(\n",
    "            shape=(1, input_shape[1], self.k), initializer=\"uniform\", trainable=True\n",
    "        )\n",
    "\n",
    "        #super().build(input_shape)\n",
    "\n",
    "    def call(self, inputs: tf.Tensor, **kwargs) -> tf.Tensor:\n",
    "\n",
    "        inputs = tf.expand_dims(inputs, axis=-1) #(batch_size, feature_size, 1)\n",
    "\n",
    "        # Linear components\n",
    "        lin = (\n",
    "            # Multiply each time dimension with the corresponding linear time component\n",
    "            tf.multiply(inputs, self.w_b)\n",
    "            # Bias component for each time dimension\n",
    "            + self.b_b\n",
    "        )\n",
    "\n",
    "        # Periodic components\n",
    "        # Multiply each time dimension (M, D, H, mins, etc.) with the corresponding frequency vector\n",
    "        per = tf.multiply(tf.tile(inputs, multiples=[1, 1, self.k]), self.freq)\n",
    "        # Phase vector for each time dimension\n",
    "        per = self.p_activation(per + self.phase)\n",
    "        return tf.concat([lin, per], -1)\n",
    "\n",
    "    def compute_output_shape(self, input_shape: tuple) -> tuple:\n",
    "       \n",
    "        return (input_shape[0], input_shape[1], self.k + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "a2ef0194",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_angles(pos, k, d):\n",
    "    i = k // 2\n",
    "    angles = pos / np.power(10000, 2 * i / d)\n",
    "\n",
    "    return angles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "cdf6be49",
   "metadata": {},
   "outputs": [],
   "source": [
    "def positional_encoding(positions, d):\n",
    "\n",
    "    angle_rads = get_angles(np.arange(positions)[:, np.newaxis],\n",
    "                            np.arange(d)[np.newaxis, :],\n",
    "                            d)\n",
    "  \n",
    "    angle_rads[:, 0::2] = np.sin(angle_rads[:, 0::2])\n",
    "  \n",
    "    angle_rads[:, 1::2] = np.cos(angle_rads[:, 1::2])\n",
    "\n",
    "    pos_encoding = angle_rads[np.newaxis, ...]\n",
    "\n",
    "    return tf.cast(pos_encoding, dtype=tf.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "86b69562",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "79b11ecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transformer_encoder(inputs, head_size, num_heads, ff_dim, dropout=0):\n",
    "    # Normalization and Attention\n",
    "    x = inputs\n",
    "    #x = layers.LayerNormalization(epsilon=1e-6)(inputs)\n",
    "    x = layers.MultiHeadAttention(\n",
    "        key_dim=head_size, num_heads=num_heads, dropout=dropout\n",
    "    )(x, x)\n",
    "    #x = layers.Dropout(dropout)(x)\n",
    "    res = x + inputs\n",
    "\n",
    "    # Feed Forward Part\n",
    "    #x = layers.LayerNormalization(epsilon=1e-6)(res)\n",
    "    #x = layers.Conv1D(filters=ff_dim, kernel_size=1, activation=\"relu\")(x)\n",
    "    #x = layers.Dropout(dropout)(x)\n",
    "    #x = layers.Conv1D(filters=inputs.shape[-1], kernel_size=1)(x)\n",
    "    return  res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "25fdc92e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_causal_attention_mask(inputs):\n",
    "        input_shape = tf.shape(inputs)\n",
    "        batch_size, sequence_length = input_shape[0], input_shape[1]\n",
    "        i = tf.range(sequence_length)[:, tf.newaxis]\n",
    "        j = tf.range(sequence_length)\n",
    "        mask = tf.cast(i >= j, dtype=\"int32\")\n",
    "        mask = tf.reshape(mask, (1, input_shape[1], input_shape[1]))\n",
    "        mult = tf.concat(\n",
    "            [tf.expand_dims(batch_size, -1), tf.constant([1, 1], dtype=tf.int32)],\n",
    "            axis=0,\n",
    "        )\n",
    "        return tf.tile(mask, mult)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "c9a9c3dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transformer_decoder(x, enc_output, head_size, num_heads, ff_dim, dropout=0, mask=None):\n",
    "    causal_mask = get_causal_attention_mask(x)\n",
    "    \n",
    "    # Normalization and Attention\n",
    "    #x = layers.LayerNormalization(epsilon=1e-6)(inputs)\n",
    "    mult_attn_out1 = layers.MultiHeadAttention(\n",
    "                            key_dim=head_size, num_heads=num_heads, dropout=dropout\n",
    "            )(x, x, x, attention_mask=causal_mask)\n",
    "    \n",
    "    #Q1 = layers.LayerNormalization(epsilon=1e-6)(mult_attn_out1 + x)\n",
    "    Q1 = mult_attn_out1 \n",
    "    mult_attn_out2 = layers.MultiHeadAttention(\n",
    "                            key_dim=head_size, num_heads=num_heads, dropout=dropout\n",
    "            )(Q1, enc_output, enc_output)\n",
    "    #Q2 = layers.LayerNormalization(epsilon=1e-6)(mult_attn_out2 + Q1)\n",
    "    Q2 = mult_attn_out2 + Q1\n",
    "    # Feed Forward Part\n",
    "    #x = layers.Conv1D(filters=ff_dim, kernel_size=1, activation=\"relu\")(Q2)\n",
    "    #x = layers.Dropout(dropout)(x)\n",
    "    #x = layers.Conv1D(filters=1, kernel_size=1)(x)\n",
    "    #out3 = x + mult_attn_out2\n",
    "    return Q2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "035d1146",
   "metadata": {},
   "outputs": [],
   "source": [
    "#layers.MultiHeadAttention?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "2318f2f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(\n",
    "        input_shape,\n",
    "        head_size,\n",
    "        num_heads,\n",
    "        ff_dim,\n",
    "        num_transformer_blocks,\n",
    "        mlp_units,\n",
    "        dropout=0,\n",
    "        mlp_dropout=0,\n",
    "    ):\n",
    "\n",
    "    embed_dim = 64\n",
    "    encoder_inputs = keras.Input(shape=input_shape, name=\"encoder_inputs\")\n",
    "    x = encoder_inputs\n",
    "    x = Time2Vec(64, \"sin\")(x)\n",
    "    #x += positional_encoding(input_shape[0],1)\n",
    "    for _ in range(num_transformer_blocks):\n",
    "            x = transformer_encoder(x, head_size, num_heads, ff_dim, dropout)\n",
    "    encoder_outputs = x\n",
    "    encoder = keras.Model(encoder_inputs, encoder_outputs)\n",
    "\n",
    "    decoder_inputs = keras.Input(shape=((input_shape[0]),input_shape[1]), name=\"decoder_inputs\")\n",
    "    encoded_seq_inputs = keras.Input(shape=(input_shape[0], embed_dim), name=\"decoder_state_inputs\")\n",
    "    x = decoder_inputs\n",
    "    x += Time2Vec(64, \"sin\")(x)\n",
    "    for _ in range(num_transformer_blocks):\n",
    "            x = transformer_decoder(x, encoded_seq_inputs, head_size, num_heads, ff_dim, dropout)\n",
    "    decoder_outputs = x\n",
    "    decoder = keras.Model([decoder_inputs, encoded_seq_inputs], decoder_outputs)\n",
    "    decoder_outputs = decoder([decoder_inputs, encoder_outputs])\n",
    "    \n",
    "    transformer = keras.Model(\n",
    "        [encoder_inputs, decoder_inputs], decoder_outputs, name=\"transformer\"\n",
    "    )\n",
    "    return transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "42af6e35",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Exception encountered when calling layer \"time2_vec\" (type Time2Vec).\n\nin user code:\n\n    File \"/tmp/ipykernel_408/3782225129.py\", line 47, in call  *\n        per = tf.multiply(tf.tile(inputs, multiples=[1, 1, self.k]), self.freq)\n\n    ValueError: Shape must be rank 4 but is rank 3 for '{{node time2_vec/Tile}} = Tile[T=DT_FLOAT, Tmultiples=DT_INT32](time2_vec/ExpandDims, time2_vec/Tile/multiples)' with input shapes: [?,11,1,1], [3].\n\n\nCall arguments received:\n  • inputs=tf.Tensor(shape=(None, 11, 1), dtype=float32)\n  • kwargs={'training': 'False'}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_408/360140278.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0minput_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m model = build_model(\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0minput_shape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mhead_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_408/2970178424.py\u001b[0m in \u001b[0;36mbuild_model\u001b[0;34m(input_shape, head_size, num_heads, ff_dim, num_transformer_blocks, mlp_units, dropout, mlp_dropout)\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mencoder_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"encoder_inputs\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder_inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTime2Vec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"sin\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m     \u001b[0;31m#x += positional_encoding(input_shape[0],1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_transformer_blocks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/cvmfs/sft.cern.ch/lcg/views/LCG_103cuda/x86_64-centos7-gcc11-opt/lib/python3.9/site-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/cvmfs/sft.cern.ch/lcg/views/LCG_103cuda/x86_64-centos7-gcc11-opt/lib/python3.9/site-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    690\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    691\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ag_error_metadata'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 692\u001b[0;31m           \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    693\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    694\u001b[0m           \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Exception encountered when calling layer \"time2_vec\" (type Time2Vec).\n\nin user code:\n\n    File \"/tmp/ipykernel_408/3782225129.py\", line 47, in call  *\n        per = tf.multiply(tf.tile(inputs, multiples=[1, 1, self.k]), self.freq)\n\n    ValueError: Shape must be rank 4 but is rank 3 for '{{node time2_vec/Tile}} = Tile[T=DT_FLOAT, Tmultiples=DT_INT32](time2_vec/ExpandDims, time2_vec/Tile/multiples)' with input shapes: [?,11,1,1], [3].\n\n\nCall arguments received:\n  • inputs=tf.Tensor(shape=(None, 11, 1), dtype=float32)\n  • kwargs={'training': 'False'}"
     ]
    }
   ],
   "source": [
    "input_shape = x_train.shape[1:]\n",
    "\n",
    "model = build_model(\n",
    "    input_shape,\n",
    "    head_size=256,\n",
    "    num_heads=4,\n",
    "    ff_dim=4,\n",
    "    num_transformer_blocks=4,\n",
    "    mlp_units=[128],\n",
    "    mlp_dropout=0.4,\n",
    "    dropout=0.25,\n",
    ")\n",
    "model.summary(expand_nested=True)\n",
    "\n",
    "#opt = SGD(lr=0.01, momentum=0.9)\n",
    "opt = tf.keras.optimizers.SGD(learning_rate=0.01, momentum=0.9)\n",
    "model.compile(loss='mean_squared_error', optimizer='adam', metrics=['mse'])\n",
    "#model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "callbacks = [keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True)]\n",
    "\n",
    "history = model.fit(\n",
    "    train_dataset,\n",
    "    epochs=15,\n",
    "    #callbacks=callbacks,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "a076c99a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BatchDataset element_spec=({'encoder_inputs': TensorSpec(shape=(None, 11, 1), dtype=tf.float64, name=None), 'decoder_inputs': TensorSpec(shape=(None, 11, 1), dtype=tf.float64, name=None)}, TensorSpec(shape=(None, 11, 1), dtype=tf.float64, name=None))>"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "3cdda3cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_sequence(input_sentence, target_sentence):\n",
    "    tokenized_input_sentence = tf.convert_to_tensor(input_sentence)\n",
    "    #decoded_sentence = np.zeros((input_sentence.shape[1]-1, 1))[ np.newaxis, ...]\n",
    "    #decoded_sentence = np.concatenate((99.0*np.ones((1,1,1)), decoded_sentence), axis=1)\n",
    "    decoded_sentence = np.reshape(target_sentence,(1,11,1))\n",
    "    \"\"\"\n",
    "    for i in range(1):\n",
    "        tokenized_target_sentence = tf.convert_to_tensor(decoded_sentence)\n",
    "        predictions = model([tokenized_input_sentence, tokenized_target_sentence])\n",
    "        #print(\"suman\",predictions)\n",
    "        if i <10:\n",
    "            decoded_sentence[0, i+1, 0] = predictions[0, i, 0]\n",
    "            #print(\"suman1\",decoded_sentence)\n",
    "    \"\"\"\n",
    "    tokenized_target_sentence = tf.convert_to_tensor(decoded_sentence)\n",
    "    predictions = model([tokenized_input_sentence, tokenized_target_sentence])\n",
    "    return decoded_sentence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "828743b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX = [np.transpose(pair)[..., np.newaxis] for pair in x_train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "e37658aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[99.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.5417028 ]\n",
      "  [ 0.96375969]\n",
      "  [ 0.96371202]\n",
      "  [ 0.78764783]\n",
      "  [ 0.58232425]\n",
      "  [ 0.40582712]]]\n",
      "[[ 99.        ]\n",
      " [  0.        ]\n",
      " [  0.        ]\n",
      " [  0.        ]\n",
      " [  0.        ]\n",
      " [  0.5417028 ]\n",
      " [  0.96375969]\n",
      " [  0.96371202]\n",
      " [  0.78764783]\n",
      " [  0.58232425]\n",
      " [  0.40582712]\n",
      " [  0.27246438]\n",
      " [-99.        ]]\n",
      "0\n",
      "[[[99.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.5417028 ]\n",
      "  [ 0.96375969]\n",
      "  [ 0.96371202]\n",
      "  [ 0.78764783]\n",
      "  [ 0.58232425]\n",
      "  [ 0.40582712]]]\n",
      "[[ 99.        ]\n",
      " [  0.        ]\n",
      " [  0.        ]\n",
      " [  0.        ]\n",
      " [  0.        ]\n",
      " [  0.5417028 ]\n",
      " [  0.96375969]\n",
      " [  0.96371202]\n",
      " [  0.78764783]\n",
      " [  0.58232425]\n",
      " [  0.40582712]\n",
      " [  0.27246438]\n",
      " [-99.        ]]\n",
      "1\n",
      "[[[99.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.5417028 ]\n",
      "  [ 0.96375969]\n",
      "  [ 0.96371202]\n",
      "  [ 0.78764783]\n",
      "  [ 0.58232425]\n",
      "  [ 0.40582712]]]\n",
      "[[ 99.        ]\n",
      " [  0.        ]\n",
      " [  0.        ]\n",
      " [  0.        ]\n",
      " [  0.        ]\n",
      " [  0.5417028 ]\n",
      " [  0.96375969]\n",
      " [  0.96371202]\n",
      " [  0.78764783]\n",
      " [  0.58232425]\n",
      " [  0.40582712]\n",
      " [  0.27246438]\n",
      " [-99.        ]]\n",
      "2\n",
      "[[[99.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.5417028 ]\n",
      "  [ 0.96375969]\n",
      "  [ 0.96371202]\n",
      "  [ 0.78764783]\n",
      "  [ 0.58232425]\n",
      "  [ 0.40582712]]]\n",
      "[[ 99.        ]\n",
      " [  0.        ]\n",
      " [  0.        ]\n",
      " [  0.        ]\n",
      " [  0.        ]\n",
      " [  0.5417028 ]\n",
      " [  0.96375969]\n",
      " [  0.96371202]\n",
      " [  0.78764783]\n",
      " [  0.58232425]\n",
      " [  0.40582712]\n",
      " [  0.27246438]\n",
      " [-99.        ]]\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "for _ in range(4):\n",
    "    input_sentence = trainX[i]\n",
    "    target_sentence = train_target[i][:-2]\n",
    "    translated = decode_sequence(input_sentence, target_sentence)\n",
    "    print(translated)\n",
    "    print(train_target[i])\n",
    "    print(i)\n",
    "    i +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "744ac287",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
